{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "326628c3",
   "metadata": {},
   "source": [
    "# Mutual Information \n",
    "\n",
    "It is a generalization of [Information content](https://en.wikipedia.org/wiki/Information_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d38523a",
   "metadata": {},
   "source": [
    "## Alphabet\n",
    "\n",
    "Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space and\n",
    "$X : \\Omega \\to \\mathbb{R}^n$ be a discrete random vector.\n",
    "Define its alphabet by\n",
    "$$\n",
    "\\text{supp}(\\mathbb{P}_{X}) = \\{x \\in \\mathbb{R} : \\mathbb{P}(X = x) > 0\\},\n",
    "$$\n",
    "where $\\mathbb{P}_{X}$ is the probability measure induced by $X$, i.e. the probability measure obtained by the Carathéodory extension theorem applied to\n",
    "\n",
    "$$\n",
    "\\mathbb{P}_{X}\\!\\left(\\prod_{i=1}^{n} B_i\\right)\n",
    "= \\mathbb{P}\\!\\left(\\bigcap_{i=1}^{n} X_i^{-1}(B_i)\\right),\n",
    "$$\n",
    "\n",
    "for any Borel set $\\prod_{i=1}^{n} B_i \\subset \\mathbb{R}^n$.\n",
    "\n",
    "**Note:** In measure theory, $\\mathbb{P}_{X}$ is called the *distribution* or *law* of $X$.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1bf838",
   "metadata": {},
   "source": [
    "## Probability Mass Function (pmf)\n",
    "\n",
    "Let\n",
    "* $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space\n",
    "* $X : \\Omega \\to \\mathbb{R}^n$ be a discrete random vector with (finite or countable) alphabet $\\mathcal{X} \\subset \\mathbb{R}$.\n",
    "\n",
    "Define the probability measure (law) induced by $X$ as\n",
    "$$\n",
    "\\begin{aligned}\n",
    "\\mathbb{P}_{X} : \\mathcal{B}(\\mathbb{R}) &\\to [0,1],\\\\\n",
    "\\mathbb{P}_{X}(B)  &= \\mathbb{P}\\big(X^{-1}(B)\\big).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The **probability mass function (pmf)** of $X$ is then the function\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p_X : \\mathcal{X} &\\to [0,1],\\\\\n",
    "p_X(x) &= \\mathbb{P}_{X}(\\{x\\}) = \\mathbb{P}(X = x).\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "**Note:**  \n",
    "\n",
    "The fundamental question of Information Theory is:\n",
    "\n",
    "How much uncertainty is in $X$ before observing it, and how much information is gained after observing it?\n",
    "\n",
    "This is not variance. It is a different notion of uncertainty based on logarithms and probability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dcfd57",
   "metadata": {},
   "source": [
    "## Definition: Pointwise Mutual Information (PMI)\n",
    "\n",
    "Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space and\n",
    "$X=(X_1,\\dots,X_n)$ and $Y=(Y_1,\\dots,Y_m)$ two discrete random vectors.\n",
    "\n",
    "We define the **pointwise mutual information** between $X$ and $Y$ as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}} &: \\mathcal{X} \\times \\mathcal{Y} \\to \\mathbb{R}\\\\\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(x,y)\n",
    "&:= \\log\\!\\left( \\frac{p_{(X,Y)}(x,y)}{p_X(x)\\,p_Y(y)} \\right),\\\\\n",
    "&= \\log\\!\\left( \\frac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(X=x)\\mathbb{P}(Y=y)} \\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The associated **pointwise mutual-information random variable** is the composition\n",
    "$$\n",
    "\\begin{align*}\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y) : \\Omega &\\to \\mathbb{R},\\\\\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)(\\omega)\n",
    "&:= \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}\\big( X(\\omega),\\,Y(\\omega)\\big).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "**Note:** We omit explicit reference to $\\mathbb{P}_{(X,Y)}$ whenever the context is clear. When no ambiguity arises, we simply write $\\operatorname{pmi}$ and $\\operatorname{pmi}(X \\Cap Y)$ in place of $\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}$ and $\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)$ respetively. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e3cd89",
   "metadata": {},
   "source": [
    "## Property: PMI Symetry\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}} (x,y)&= \\operatorname{pmi}_{\\mathbb{P}_{(Y,X)}} (y,x) \\\\\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y) &= I_{\\mathbb{P}_{(Y,X)}}(Y \\Cap X)\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4987511",
   "metadata": {},
   "source": [
    "**Proof:** \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}} (x,y)&=\\log\\!\\left( \\frac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(X=x)\\mathbb{P}(Y=y)} \\right),\\\\\n",
    "&=\\log\\!\\left( \\frac{\\mathbb{P}(Y=y,X=x)}{\\mathbb{P}(Y=y)\\mathbb{P}(X=x)} \\right),\\\\\n",
    "&= \\operatorname{pmi}_{\\mathbb{P}_{(Y,X)}} (y,x) \\\\\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)(\\omega) &= \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}\\big( X(\\omega),\\,Y(\\omega)\\big),\\\\\n",
    "&= \\operatorname{pmi}_{\\mathbb{P}_{(Y,X)}}\\big(Y(\\omega), X(\\omega)\\,\\big),\\\\\n",
    "&=I_{\\mathbb{P}_{(Y,X)}}(Y \\Cap X)(\\omega).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfe9defc",
   "metadata": {},
   "source": [
    "## Property: PMI independance\n",
    "$$\n",
    "\\begin{align*}\n",
    "X\\perp Y &\\iff \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(x,y)=0,\\quad (x,y)\\in\\mathcal{(X, Y)} \\\\\n",
    "X\\perp Y &\\iff I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)=0.\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab64a1f",
   "metadata": {},
   "source": [
    "**Proof:**\n",
    "lets denote the alphabet of $(X,Y)$ by $\\mathcal{(X, Y)}$ then we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "X\\perp Y &\\iff \\mathbb{P}(X=x,Y=y)=\\mathbb{P}(X=x)\\mathbb{P}(Y=y),\\quad (x,y)\\in\\mathcal{(X, Y)}\\\\\n",
    "&\\iff \\frac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(X=x)\\mathbb{P}(Y=y)}=1,\\quad (x,y)\\in\\mathcal{(X, Y)}\\\\\n",
    "&\\iff \\log\\left(\\frac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(X=x)\\mathbb{P}(Y=y)}\\right)=0,\\quad (x,y)\\in\\mathcal{(X, Y)}\\\\\n",
    "&\\iff \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(x,y)=0,\\quad (x,y)\\in\\mathcal{(X, Y)} \\\\\n",
    "&\\iff \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)=0,\\\\\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "568ec875",
   "metadata": {},
   "source": [
    "## Definition: Pointwise Information Content\n",
    "\n",
    "Let $(\\Omega, \\mathcal{F}, \\mathbb{P})$ be a probability space and\n",
    "$X=(X_1,\\dots,X_n)$ a discrete random vector.\n",
    "\n",
    "We define the **pointwise information content of $X$** as\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "I_{\\mathbb{P}_{X}} &: \\mathcal{X} \\to \\mathbb{R}_+\\\\\n",
    "I_{\\mathbb{P}_{X}}(x) &:= \\operatorname{pmi}_{\\mathbb{P}_{(X,X)}}(x,x),\\\\\n",
    "&= \\log\\!\\left( \\frac{p_{(X,X)}(x,x)}{p_X(x)\\,p_X(x)} \\right),\\\\\n",
    "&= \\log\\!\\left( \\frac{\\mathbb{P}(X=x,X=x)}{\\mathbb{P}(X=x)\\mathbb{P}(X=y)} \\right),\\\\\n",
    "&= \\log\\!\\left( \\frac{\\mathbb{P}(X=x)}{\\mathbb{P}(X=x)\\mathbb{P}(X=y)} \\right),\\\\\n",
    "&= -\\log\\!\\left(\\mathbb{P}(X=x) \\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "The associated **pointwise information-content random variable** is the composition\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "I_{\\mathbb{P}_{X}}(X) : \\Omega &\\to \\mathbb{R}_+,\\\\\n",
    "I_{\\mathbb{P}_{X}}(X)(\\omega)\n",
    "&:= I_{\\mathbb{P}_{X}}\\big( X(\\omega)\\big).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "\n",
    "\n",
    "**Iterpretation:**  \n",
    "- If an outcome $x$ has **small probability**, then $I_{\\mathbb{P}_X}(x)$ is **large** → the outcome is *very surprising*.  \n",
    "- If an outcome $x$ has **large probability**, then $I_{\\mathbb{P}_X}(x)$ is **small** → the outcome is *barely surprising*.  \n",
    "- In other words, **information content measures how surprising a specific realization is.**\n",
    "\n",
    "**Note:** \n",
    "* We omit explicit reference to $\\mathbb{P}_X$ whenever the context is clear. When no ambiguity arises, we simply write $I(x)$ in place of $I_{\\mathbb{P}_X}(x)$. \n",
    "* $I_{\\mathbb{P}_{X}}$ is a particular case of the information content defined on the probability space \n",
    "  $(\\mathbb{R}^n,\\, \\mathcal{B}(\\mathbb{R}^n),\\, \\mathbb{P}_{X})$ \n",
    "  (or equivalently on $(\\mathcal{X}, \\mathcal{P}(\\mathcal{X}), \\mathbb{P}_{X})$ in the purely discrete case, where $\\mathcal{X}$ is the alphabet of $X$). \n",
    "  Here we identify the singleton $\\{x\\}$ with its element $x$ via\n",
    "  $$\n",
    "  I_{\\mathbb{P}_X}(x) := I_{\\mathbb{P}_X}(\\{x\\}).\n",
    "  $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4ddd4c9",
   "metadata": {},
   "source": [
    "### Property: Equivalent Form\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(x,y)&=I_{\\mathbb{P}_{X}}(x)+I_{\\mathbb{P}_{Y}}(y)-I_{\\mathbb{P}_{(X,Y)}}(x,y),\\\\\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X\\Cap Y)&=I_{\\mathbb{P}_{X}}(X)+I_{\\mathbb{P}_{Y}}(Y)-I_{\\mathbb{P}_{(X,Y)}}(X,Y).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6360e2",
   "metadata": {},
   "source": [
    "**Proof:** For the pmi function we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}(x,y)\n",
    "&= \\log\\!\\left( \\frac{\\mathbb{P}(X=x,Y=y)}{\\mathbb{P}(X=x)\\mathbb{P}(Y=y)} \\right),\\\\\n",
    "&= -\\log\\!\\left(\\mathbb{P}(X=x) \\right)-\\log\\!\\left( \\mathbb{P}(Y=y) \\right)+\\log\\!\\left(\\mathbb{P}(X=x,Y=y)\\right),\\\\\n",
    "&=I_{\\mathbb{P}_{X}}(x)+I_{\\mathbb{P}_{Y}}(y)-I_{\\mathbb{P}_{(X,Y)}}(x,y).\n",
    "\\end{align*}\n",
    "$$\n",
    "and for the ramdom variable we only use the result for the function and the defintions\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "I_{\\mathbb{P}_{(X,Y)}}(X \\Cap Y)(\\omega)\n",
    "&:= \\operatorname{pmi}_{\\mathbb{P}_{(X,Y)}}\\big( X(\\omega),\\,Y(\\omega)\\big),\\\\\n",
    "&=I_{\\mathbb{P}_{X}}(X(\\omega))+I_{\\mathbb{P}_{Y}}(Y(\\omega))-I_{\\mathbb{P}_{(X,Y)}}(X(\\omega),\\,Y(\\omega)),\\\\\n",
    "&=I_{\\mathbb{P}_{X}}(X(\\omega))+I_{\\mathbb{P}_{Y}}(Y(\\omega))-I_{\\mathbb{P}_{(X,Y)}}((X,Y)(\\omega)),\\\\\n",
    "&=I_{\\mathbb{P}_{X}}(X)(\\omega)+I_{\\mathbb{P}_{Y}}(Y)(\\omega)-I_{\\mathbb{P}_{(X,Y)}}(X,Y)(\\omega),\\\\\n",
    "&=(I_{\\mathbb{P}_{X}}(X)+I_{\\mathbb{P}_{Y}}(Y)-I_{\\mathbb{P}_{(X,Y)}}(X,Y))(\\omega).\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7b8fc5",
   "metadata": {},
   "source": [
    "### Property: Independence of random vectors add their information contents\n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "X\\perp Y &\\iff I_{\\mathbb{P}_{(X,Y)}}(x,y) = I_{\\mathbb{P}_{X}}(x)+I_{\\mathbb{P}_{Y}}(y),\\quad (x,y)\\in\\mathcal{X}\\times\\mathcal{Y}\\\\\n",
    "X\\perp Y &\\iff I_{\\mathbb{P}_{(X,Y)}}(X, Y) = I_{\\mathbb{P}_{X}}(X) + I_{\\mathbb{P}_{Y}}(Y).\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf39527",
   "metadata": {},
   "source": [
    "**Proof:** It is a direct consequence of the mutual information independance property."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ffa117",
   "metadata": {},
   "source": [
    "## Code: Information Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "351f809e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d73e0527",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inf_cont(P):\n",
    "    return -np.log2(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46464fd0",
   "metadata": {},
   "source": [
    "### Arbitrary example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a327c6",
   "metadata": {},
   "source": [
    "\n",
    "#### Define discrete probability vector\n",
    "\n",
    "Consider the alphabets\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{X}&=\\{0,1,2\\},\\\\\n",
    "\\mathcal{Y}&=\\{0,1\\}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Define the joint probability mass function $p:\\mathcal{X}\\times\\mathcal{Y}\\to[0,1]$ by\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(0,0)&=0.05, & p(0,1)&=0.15,\\\\\n",
    "p(1,0)&=0.20, & p(1,1)&=0.10,\\\\\n",
    "p(2,0)&=0.30, & p(2,1)&=0.20.\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10343dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Joint probability matrix p(x,y)\n",
    "#.   Y=0    Y=1\n",
    "P_XY = np.array([\n",
    "    [0.05, 0.15],   # X = 0\n",
    "    [0.20, 0.10],   # X = 1\n",
    "    [0.30, 0.20]    # X = 2\n",
    "])\n",
    "\n",
    "# Generate (i, j) pairs in the same order as flatten()\n",
    "values = np.array([(i, j) for i in range(P_XY.shape[0])\n",
    "                          for j in range(P_XY.shape[1])])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ddce27",
   "metadata": {},
   "source": [
    "#### Check variable independance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6456255a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_(X)P(Y)(x,y)=\n",
      "[[0.11  0.09 ]\n",
      " [0.165 0.135]\n",
      " [0.275 0.225]]\n",
      "P_(X,Y)(x,y)=\n",
      "[[0.05 0.15]\n",
      " [0.2  0.1 ]\n",
      " [0.3  0.2 ]]\n"
     ]
    }
   ],
   "source": [
    "P_X = P_XY.sum(axis=1)  # Marginal probabilities for X\n",
    "P_Y = P_XY.sum(axis=0)  # Marginal probabilities for Y\n",
    "P_XP_Y = np.outer(P_X, P_Y)  # Product of marginals\n",
    "print(f\"P_(X)P(Y)(x,y)=\\n{P_XP_Y}\")\n",
    "print(f\"P_(X,Y)(x,y)=\\n{P_XY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89d7099b",
   "metadata": {},
   "source": [
    "#### Information content\n",
    "\n",
    "$$I(x,y) = -\\log_2\\big(p(x,y)\\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5f971e14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(x,y)=\n",
      "[[4.32192809 2.73696559]\n",
      " [2.32192809 3.32192809]\n",
      " [1.73696559 2.32192809]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"I(x,y)=\\n{inf_cont(P_XY)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79493f94",
   "metadata": {},
   "source": [
    "notice that more unlikeley(unpredictable) values has higher infomraiton content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bf1456",
   "metadata": {},
   "source": [
    "#### Information content random vector\n",
    "\n",
    "$$I(X,Y) = -\\log_2\\big(p(X,Y)\\big)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15d718f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PMF of I(X,Y) samples:\n",
      "{3.321928094887362: 0.0964, 2.736965594166206: 0.1549, 1.7369655941662063: 0.2956, 2.321928094887362: 0.4038, 4.321928094887363: 0.0493}\n",
      "\n",
      "inf_cont(P_XY)=array([[4.32192809, 2.73696559],\n",
      "       [2.32192809, 3.32192809],\n",
      "       [1.73696559, 2.32192809]])\n",
      "P_XY=array([[0.05, 0.15],\n",
      "       [0.2 , 0.1 ],\n",
      "       [0.3 , 0.2 ]])\n"
     ]
    }
   ],
   "source": [
    "def I_sample(P,values,n):\n",
    "    idx = np.random.choice(len(P), size=n, p=P)\n",
    "    return values[idx]\n",
    "\n",
    "I_P = P_XY.flatten()\n",
    "I_values = inf_cont(P_XY).flatten()\n",
    "samples = I_sample(I_P,I_values,n=10_000)\n",
    "counts = Counter(samples)\n",
    "\n",
    "I_pmf = {val.item():count/len(samples) for val,count in counts.items()}\n",
    "print(f\"PMF of I(X,Y) samples:\\n{I_pmf}\")\n",
    "print(f\"\\n{inf_cont(P_XY)=}\")\n",
    "print(f\"{P_XY=}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e382d4",
   "metadata": {},
   "source": [
    "### Independent example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35955bae",
   "metadata": {},
   "source": [
    "#### Define discrete probability vector\n",
    "\n",
    "Consider the alphabets\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\mathcal{X}&=\\{0,1,2\\},\\\\\n",
    "\\mathcal{Y}&=\\{0,1\\}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Define the joint probability mass function $p:\\mathcal{X}\\times\\mathcal{Y}\\to[0,1]$ by\n",
    "$$\n",
    "\\begin{aligned}\n",
    "p(0,0)&=0.08, & p(0,1)&=0.12,\\\\\n",
    "p(1,0)&=0.20, & p(1,1)&=0.30,\\\\\n",
    "p(2,0)&=0.12, & p(2,1)&=0.18.\n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "90d53f29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_(X,Y)(x,y)=\n",
      "[[0.08 0.12]\n",
      " [0.2  0.3 ]\n",
      " [0.12 0.18]]\n"
     ]
    }
   ],
   "source": [
    "# Joint probability matrix p(x,y)\n",
    "#.   Y=0    Y=1\n",
    "P_XY = np.array([\n",
    "    [0.08, 0.12],   # X = 0\n",
    "    [0.20, 0.30],   # X = 1\n",
    "    [0.12, 0.18]    # X = 2\n",
    "])\n",
    "\n",
    "# Check if it's a valid probability distribution\n",
    "if  P_XY.sum() == 1:\n",
    "    print(f\"P_(X,Y)(x,y)=\\n{P_XY}\")\n",
    "else:\n",
    "    print(\"Error: The probabilities do not sum to 1.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e99970",
   "metadata": {},
   "source": [
    "#### Check variable independance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d726919",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "P_(X)P(Y)(x,y)=\n",
      "[[0.08 0.12]\n",
      " [0.2  0.3 ]\n",
      " [0.12 0.18]]\n",
      "P_(X,Y)(x,y)=\n",
      "[[0.08 0.12]\n",
      " [0.2  0.3 ]\n",
      " [0.12 0.18]]\n"
     ]
    }
   ],
   "source": [
    "P_X = P_XY.sum(axis=1)  # Marginal probabilities for X\n",
    "P_Y = P_XY.sum(axis=0)  # Marginal probabilities for Y\n",
    "P_XP_Y = np.outer(P_X, P_Y)  # Product of marginals\n",
    "print(f\"P_(X)P(Y)(x,y)=\\n{P_XP_Y}\")\n",
    "print(f\"P_(X,Y)(x,y)=\\n{P_XY}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec7295d9",
   "metadata": {},
   "source": [
    "### Property: Independence of random vectors add their information\n",
    "\n",
    "If $X$ and $Y$ are independent random vectors, then\n",
    "$$\n",
    "\\begin{align*}\n",
    "I(x,y) &= I(x)+I(y),\\\\\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ec9fde8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(x,y)=\n",
      "[[3.64385619 3.05889369]\n",
      " [2.32192809 1.73696559]\n",
      " [3.05889369 2.47393119]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"I(x,y)=\\n{inf_cont(P_XY)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5bf7224f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I(x)+I(y)=\n",
      "[[3.64385619 3.05889369]\n",
      " [2.32192809 1.73696559]\n",
      " [3.05889369 2.47393119]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"I(x)+I(y)=\\n{inf_cont(P_X)[:,None]+inf_cont(P_Y)[None,:]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-notebook",
   "language": "python",
   "name": "ml-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
