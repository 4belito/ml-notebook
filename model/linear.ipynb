{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "be540389",
   "metadata": {},
   "source": [
    "# Linear Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a501a77",
   "metadata": {},
   "source": [
    "## Math"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d9c726e",
   "metadata": {},
   "source": [
    "Input\n",
    "* $x \\in \\mathbb{R}^{d_{in}}$ \n",
    "\n",
    "Weights\n",
    "* weight $W \\in \\mathbb{R}^{d_{out}\\times d_{in}}$ \n",
    "* bias $b \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "Output\n",
    "* $o \\in \\mathbb{R}^{d_{out}}$\n",
    "\n",
    "$$o = \\text{Linear}_{W,b}(x)=Wx+b.$$\n",
    "\n",
    "**Note:** In practice we also have a batch dimension and the inputs takes the form $X\\in \\mathbb{R}^{d_{batch}\\times d_{in}}$ so the immplementation takes the form \n",
    "\n",
    "$$O = \\text{Linear}_{W,b}(X)=XW^{T}+B,$$\n",
    "where\n",
    "$$B=[b|b|\\dots|b]^T\\in \\mathbb{R}^{d_{batch},d_{out}}.$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76697be6",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "e03cbd85",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "067534f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "1.6732632423543772"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5ae28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Linear(nn.Module):\n",
    "    def __init__(\n",
    "        self, input_dim, output_dim, bias=True, device=None, dtype=None, init_activation=None\n",
    "    ):\n",
    "        super().__init__()\n",
    "        W = torch.empty(output_dim, input_dim, device=device, dtype=dtype)\n",
    "        self.weight = nn.Parameter(W)\n",
    "        match init_activation:\n",
    "            case None:\n",
    "                nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "            case 'relu':\n",
    "                nn.init.kaiming_uniform_(self.weight, a=0, nonlinearity='relu')\n",
    "            case 'leaky_relu' | 'prelu':\n",
    "                nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5), nonlinearity='leaky_relu')\n",
    "            case 'selu':\n",
    "                alpha = 1.6732632423543772\n",
    "                nn.init.normal_(self.weight, mean=0, std=math.sqrt(1 / input_dim) * math.sqrt(1 + alpha ** 2))\n",
    "            case 'elu':\n",
    "                gain=nn.init.calculate_gain('elu')\n",
    "                nn.init.xavier_uniform_(self.weight, gain=gain)\n",
    "            case 'gelu':\n",
    "                gain=nn.init.calculate_gain('gelu')\n",
    "                nn.init.xavier_uniform_(self.weight, gain=gain)\n",
    "            case 'tanh':\n",
    "                gain = nn.init.calculate_gain('tanh')\n",
    "                nn.init.xavier_uniform_(self.weight, gain=gain)\n",
    "            case 'sigmoid':\n",
    "                gain = nn.init.calculate_gain('sigmoid')\n",
    "                nn.init.xavier_uniform_(self.weight, gain=gain)\n",
    "            \n",
    "        if bias:\n",
    "            b = torch.empty(output_dim, device=device, dtype=dtype)\n",
    "            self.bias = nn.Parameter(b)\n",
    "            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(self.weight)\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = x @ self.weight.T\n",
    "        if self.bias is not None:\n",
    "            out += self.bias\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bed06ebe",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c1626058",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4\n",
    "in_dim = 5\n",
    "out_dim = 3\n",
    "\n",
    "bias = False\n",
    "device = 'mps'\n",
    "dtype = torch.float32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "e2175352",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(batch_size, in_dim).to(device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b05252f",
   "metadata": {},
   "source": [
    "### Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6db9c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_linear = nn.Linear(in_dim, out_dim, bias=bias,device=device, dtype=dtype)\n",
    "linear = Linear(in_dim, out_dim, bias=bias, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "c558f0bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "for name, param in torch_linear.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "cd5a3ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([3, 5])\n"
     ]
    }
   ],
   "source": [
    "for name, param in linear.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f116e5c",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "f3367307",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10fd1f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(seed)\n",
    "torch_linear = nn.Linear(in_dim, out_dim, bias=bias,device=device, dtype=dtype)\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "linear = Linear(in_dim, out_dim, bias=bias, device=device, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2d1705ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5044, -0.2027, -0.0019],\n",
       "        [-0.2299,  0.4194, -0.1675],\n",
       "        [ 0.6229,  0.3113,  0.2739],\n",
       "        [ 0.5654, -1.1222, -0.3983]], device='mps:0', grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "cda91ccc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.5044, -0.2027, -0.0019],\n",
       "        [-0.2299,  0.4194, -0.1675],\n",
       "        [ 0.6229,  0.3113,  0.2739],\n",
       "        [ 0.5654, -1.1222, -0.3983]], device='mps:0',\n",
       "       grad_fn=<LinearBackward0>)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c650089",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
