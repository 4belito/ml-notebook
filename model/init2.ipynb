{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11f78e4",
   "metadata": {},
   "source": [
    "## Property: Constant initialization does not work\n",
    "\n",
    "Constant $0$ initialization could be a good idea because no bias is introduced but this creates a symetry in the weights that gradients updates can't break."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88de1",
   "metadata": {},
   "source": [
    "\n",
    "Consider a simple two layer multilayer perceptrom\n",
    "$$\\text{Linear2}_{W^{(2)},b^{(2)}}(\\text{Activtion}(\\text{Linear1}_{W^{(1)},b^{(1)}}(x)))$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Linear1}_{W^{(1)},b^{(1)}}(x)&=W^{(1)}x+b^{(1)},\\\\\n",
    "\\text{Linear2}_{W^{(2)},b^{(1)}}(x)&=W^{(2)}x+b^{(2)},\n",
    "\\end{align*}\n",
    "$$\n",
    "and $\\text{Activtion}$ is an arbitrary real function applied componentwise over vectors. \n",
    "\n",
    "Consider the properties\n",
    "* $W^{(1)}$ has constant columns (i.e. $W^{(1)}_{i,j}=c^{(1)}_j, \\ \\forall\\ i,j$)\n",
    "* $b^{(1)}$ is constant (i.e. $b^{(1)}_{i}=d^{(1)}, \\ \\forall\\ i$)\n",
    "* $W^{(2)}$ is constant (i.e. $W^{(2)}_{i,j}=c^{(2)}, \\ \\forall\\ i,j$)\n",
    "* $b^{(2)}$ is constant (i.e. $b^{(2)}_{i}=d^{(2)}, \\ \\forall\\ i$)\n",
    "\n",
    "We assume alse that the loss funciton is permutation invariant $\\text{loss}(\\pi(x))=\\text{loss}(\\pi(x))$ for any (index) permutation $x$. This is not restrictive at all. It is easy to check that Mean square loss is permutation equivariant \n",
    "$$\\text{MSE}(\\pi(x))=\\sum_{i=1}x_{\\pi(i)}^2=\\sum_{i=1}x_{i}^2=\\text{MSE}(x).$$\n",
    "This implies that the derivative are equal\n",
    "$$\\frac{\\partial f}{x_{j}}(x)=\\lim_{h\\to0}\\frac{f(x+he_{j})-f(x)}{h}=\\lim_{h\\to0}\\frac{f(x+he_{i})-f(x)}{h}=\\frac{\\partial f}{x_{i}}(x),$$\n",
    "where in the second equlity weappliy the permutation that swap $i$ and $j$.\n",
    "\n",
    "Under this condition, if the initial weights satiesfy these properties then, these properties are preserved along epochs (after the weights are updated with the gradient information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f84ed3",
   "metadata": {},
   "source": [
    "**Proof:**\n",
    "Consider\n",
    "* $W^{(1)}_{i,j}=c^{(1)}_j, \\ \\forall\\ i,j$\n",
    "* $b^{(1)}_{i}=d^{(1)}, \\ \\forall\\ i$\n",
    "* $W^{(2)}_{i,j}=c^{(2)}, \\ \\forall\\ i,j$\n",
    "* $b^{(2)}_{i}=d^{(2)}, \\ \\forall\\ i$\n",
    "\n",
    "and let's adopt the following notatioin:\n",
    "\\begin{align*}\n",
    "y^{(1)} &= \\text{Linear1}_{W^{(1)},b^{(1)}}(x),\\\\\n",
    "y^{(a)} &= \\text{Activtion}(y^{(1)}),\\\\\n",
    "y^{(2)} &= \\text{Linear2}_{W^{(2)},b^{(2)}}(y^{(a)}).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebe636",
   "metadata": {},
   "source": [
    "First notice that under this properites the output of the first layer is constant:\n",
    "$$\n",
    "\\begin{align*}\n",
    "y^{(1)}&=\\text{Linear1}_{W^{(1)},b^{(1)}}(x),\\\\\n",
    "&=W^{(1)}x+b^{(1)}=\\begin{pmatrix}\n",
    "\\sum_{j}w^{(1)}_{1,j}x_j +b^{(1)}_1\\\\ \n",
    "\\sum_{j}w^{(1)}_{2,j}x_j +b^{(1)}_2\\\\ \n",
    "\\vdots\\\\\n",
    "\\sum_{j}w^{(1)}_{N_1,j}x_j +b^{(1)}_{N_1}\\\\ \n",
    "\\end{pmatrix}\n",
    "=\\begin{pmatrix}\n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\vdots\\\\\n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\end{pmatrix}\\\\\n",
    "&=\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_1}.\\\\\n",
    "y^{(a)}&=\\text{Activation}(y^{(1)}),\\\\\n",
    "&=\\text{Activation}\\left(\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_a}\\right),\\\\\n",
    "&=\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_a},\\\\\n",
    "y^{(2)}&=\\text{Linear1}_{W^{(2)},b^{(2)}}(y^{(a)}),\\\\\n",
    "&=W^{(2)}y^{(a)}+b^{(2)},\\\\\n",
    "&=\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)W^{(2)}1_{N_2}+b^{(2)},\\\\\n",
    "&=\\left(N_2c^{(2)}\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)+d^{(2)}\\right)1_{N_2}.\n",
    "\\end{align*}\\\\\n",
    "$$\n",
    "So, all the vectors $y^{(1)},y^{(a)},y^{(2)}$ are constant. Let's denote for all $i$-th component $y^{(1)}_i=o^{(1)}$,$y^{(a)}_i=o^{(a)}$ and $y_i^{(2)}=o^{(2)}$, then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61394f",
   "metadata": {},
   "source": [
    "Then\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial w^{(1)}_{i,j}}&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}\\frac{\\partial y^{(2)}}{\\partial y^{(a)}_{i}}\\frac{\\partial y^{(a)}_{i}}{\\partial y^{(1)}_{i}}\\frac{\\partial y^{(1)}_{i}}{\\partial w^{(1)}_{i,j}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}W^{(2)}_{:,i}\\frac{\\partial \\text{Activation}}{\\partial x_{i}}(y^{(1)}_i)x_j,\\\\\n",
    "\n",
    "&=\\left(\\sum_k\\frac{\\partial \\text{loss}}{\\partial y_k}(y^{(2)}_k)W^{(2)}_{k,i}\\right)\\frac{\\partial \\text{Activation}}{\\partial x}(o^{(1)})x_j,\\\\\n",
    "&=N_2\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})c^{(2)}\\frac{\\partial \\text{Activation}}{\\partial x}\\left(o^{(1)}\\right)x_j,\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Then $\\frac{\\partial \\text{loss}}{\\partial w^{(1)}_{i,j}}$ is constant along index $i$ and consequently $W^{(1)}$ has constant columns after being updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd389e1",
   "metadata": {},
   "source": [
    "The results forthe bias $b^{(1)}$ is analogous, notice that\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial b^{(1)}_{i}}&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}\\frac{\\partial y^{(2)}}{\\partial y^{(a)}_{i}}\\frac{\\partial y^{(a)}_{i}}{\\partial y^{(1)}_{i}}\\frac{\\partial y^{(1)}_{i}}{\\partial b^{(1)}_{i}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}W^{(2)}_{:,i}\\frac{\\partial \\text{Activation}}{\\partial x_{i}}(y^{(1)}_i)\\cdot 1,\\\\\n",
    "&=\\left(\\sum_k\\frac{\\partial \\text{loss}}{\\partial y_k}(y^{(2)}_k)W^{(2)}_{k,i}\\right)\\frac{\\partial \\text{Activation}}{\\partial x}\\left(\\sum_{k}c^{(1)}_{k}x_k+d^{(1)}\\right),\\\\\n",
    "&=N_2\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})c^{(2)}\\frac{\\partial \\text{Activation}}{\\partial x}\\left(\\sum_{k}c^{(1)}_{k}x_k+d^{(1)}\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "So, $\\frac{\\partial \\text{loss}}{\\partial b^{(1)}_{i}}$ is independent of $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965f9cb",
   "metadata": {},
   "source": [
    "For the second weights we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial W^{(2)}_{i,j}}&=\\frac{\\partial \\text{loss}}{\\partial y_i^{(2)}}\\frac{\\partial y_i^{(2)}}{\\partial W^{(2)}_{i,j}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y_i}(y_i^{(2)})y^{(a)}_j,\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})o^{(a)}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Finally, for the bias wehave\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial b^{(2)}_{i}}&=\\frac{\\partial \\text{loss}}{\\partial y_i^{(2)}}\\frac{\\partial y_i^{(2)}}{\\partial b^{(2)}_{i}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y_i}(y_i^{(2)})\\cdot 1,\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)}).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then all four properties are preserved after adding an scaled gradiant vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8815c",
   "metadata": {},
   "source": [
    "## Code: Constant initializtion does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a42e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4586e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstInit(nn.Module):\n",
    "    def __init__(self, init_w: float,init_b: float,layer_dims = [3,2,4],bias: bool = False):\n",
    "        super().__init__()  \n",
    "        d1,d2,d3 = layer_dims\n",
    "        self.linear1 = nn.Linear(d1, d2,bias=bias)\n",
    "        self.linear2 = nn.Linear(d2, d3,bias=bias)\n",
    "        if bias:\n",
    "            nn.init.constant_(self.linear1.bias, init_b)\n",
    "            nn.init.constant_(self.linear2.bias, init_b)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Each column j gets value init_value + j\n",
    "        col_values = init_w + torch.arange(d1).float()  # shape (in_f,)\n",
    "\n",
    "        # Repeat for each row\n",
    "        W = col_values.unsqueeze(0).repeat(d2, 1)  # shape (out_f, in_f)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.linear1.weight.copy_(W)\n",
    "      \n",
    "        nn.init.constant_(self.linear2.weight, init_w)  \n",
    "    \n",
    "    def print_parameters(self):\n",
    "        for name , w in self.named_parameters():\n",
    "            print(name, w)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.linear1(x)\n",
    "        x_relu = self.relu(x1)\n",
    "        x2= self.linear2(x_relu)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8f0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([0.5000, 0.5000], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = ConstInit(init_w=1.0,init_b=0.5,bias=True)\n",
    "net.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce87575",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a0d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[1.6657, 1.6657, 1.6657, 1.6657],\n",
      "        [3.4921, 3.4921, 3.4921, 3.4921],\n",
      "        [6.7266, 6.7266, 6.7266, 6.7266],\n",
      "        [2.6986, 2.6986, 2.6986, 2.6986]], grad_fn=<AddmmBackward0>)\n",
      "Target: tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "y = torch.full((4, 4), 1.0)\n",
    "out = net(x)\n",
    "print(\"Output:\", out)\n",
    "print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4f703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041ab103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[1.2768, 1.6750, 2.8157],\n",
      "        [1.2768, 1.6750, 2.8157]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-0.0291, -0.0291], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.7023, 0.7023],\n",
      "        [0.7023, 0.7023],\n",
      "        [0.7023, 0.7023],\n",
      "        [0.7023, 0.7023]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.3677, 0.3677, 0.3677, 0.3677], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[0.7862, 0.0144, 1.5737],\n",
      "        [0.7862, 0.0144, 1.5737]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.0714, -1.0714], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[-1.7447, -1.7447],\n",
      "        [-1.7447, -1.7447],\n",
      "        [-1.7447, -1.7447],\n",
      "        [-1.7447, -1.7447]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([-0.0033, -0.0033, -0.0033, -0.0033], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.7547, 0.7547, 0.7547, 0.7547], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.9170, 0.9170, 0.9170, 0.9170], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.1211, 1.1211, 1.1211, 1.1211], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.3651, 1.3651, 1.3651, 1.3651], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.6468, 1.6468, 1.6468, 1.6468], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.9645, 1.9645, 1.9645, 1.9645], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([2.3162, 2.3162, 2.3162, 2.3162], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([2.7004, 2.7004, 2.7004, 2.7004], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([3.1154, 3.1154, 3.1154, 3.1154], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([3.5596, 3.5596, 3.5596, 3.5596], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([4.0317, 4.0317, 4.0317, 4.0317], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([4.5301, 4.5301, 4.5301, 4.5301], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([5.0536, 5.0536, 5.0536, 5.0536], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([5.6009, 5.6009, 5.6009, 5.6009], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([6.1708, 6.1708, 6.1708, 6.1708], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([6.7623, 6.7623, 6.7623, 6.7623], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([7.3742, 7.3742, 7.3742, 7.3742], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([8.0055, 8.0055, 8.0055, 8.0055], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([8.6552, 8.6552, 8.6552, 8.6552], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([9.3224, 9.3224, 9.3224, 9.3224], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([10.0063, 10.0063, 10.0063, 10.0063], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([10.7060, 10.7060, 10.7060, 10.7060], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([11.4207, 11.4207, 11.4207, 11.4207], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([12.1497, 12.1497, 12.1497, 12.1497], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([12.8922, 12.8922, 12.8922, 12.8922], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([13.6476, 13.6476, 13.6476, 13.6476], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([14.4152, 14.4152, 14.4152, 14.4152], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([15.1944, 15.1944, 15.1944, 15.1944], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([15.9847, 15.9847, 15.9847, 15.9847], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([16.7855, 16.7855, 16.7855, 16.7855], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([17.5962, 17.5962, 17.5962, 17.5962], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([18.4164, 18.4164, 18.4164, 18.4164], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([19.2456, 19.2456, 19.2456, 19.2456], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([20.0833, 20.0833, 20.0833, 20.0833], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([20.9291, 20.9291, 20.9291, 20.9291], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([21.7827, 21.7827, 21.7827, 21.7827], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([22.6435, 22.6435, 22.6435, 22.6435], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([23.5114, 23.5114, 23.5114, 23.5114], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([24.3858, 24.3858, 24.3858, 24.3858], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([25.2665, 25.2665, 25.2665, 25.2665], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([26.1532, 26.1532, 26.1532, 26.1532], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([27.0455, 27.0455, 27.0455, 27.0455], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([27.9433, 27.9433, 27.9433, 27.9433], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([28.8461, 28.8461, 28.8461, 28.8461], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([29.7538, 29.7538, 29.7538, 29.7538], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([30.6661, 30.6661, 30.6661, 30.6661], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([31.5828, 31.5828, 31.5828, 31.5828], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[ -6.9880, -13.5042, -10.0557],\n",
      "        [ -6.9880, -13.5042, -10.0557]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-6.3613, -6.3613], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691],\n",
      "        [0.9691, 0.9691]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([32.5037, 32.5037, 32.5037, 32.5037], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    loss = loss_fn(net(x+i), y+i)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    net.print_parameters()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
