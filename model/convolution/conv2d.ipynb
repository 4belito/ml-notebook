{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7eb6cfe9",
   "metadata": {},
   "source": [
    "# Convolutions\n",
    "\n",
    "[link](https://ut.philkr.net/deeplearning/convolution/convolutions/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbdff054",
   "metadata": {},
   "source": [
    "## Definition: Infinite 2D Convolution\n",
    "\n",
    "Input  \n",
    "* $X \\in \\mathbb{R}^{C_1\\times \\mathbb{Z}^2}.$  \n",
    "\n",
    "Weights  \n",
    "* kernel $W \\in \\mathbb{R}^{C_2\\times C_1 \\times h \\times w}$  \n",
    "* bias $b \\in \\mathbb{R}^{C_2}$  \n",
    "\n",
    "Hyperparameters  \n",
    "* stride $s=(s_1,s_2)$    \n",
    "\n",
    "Output  \n",
    "* $\\operatorname{InfConv2d}_{W,b}(X) = O \\in \\mathbb{R}^{C_2\\times \\mathbb{Z}^2}$, where  \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "O_{i,j,k} &= b_{i} + \\sum_{l=1}^{C_1} \\sum_{m=1}^{h} \\sum_{n=1}^{w}\n",
    "x_{l,\\,(j-1)\\cdot s_1 + m,\\, (k-1)\\cdot s_2 + n}\\,\n",
    "\\omega_{i,l,m,n}.\n",
    "\\end{align*}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65e049af",
   "metadata": {},
   "source": [
    "### Property: $\\operatorname{InfConv2d}_{W,0}$ is linear and $\\operatorname{InfConv2d}_{W,b}$ is affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00f0460",
   "metadata": {},
   "source": [
    "Proof:\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{InfConv2d}_{W,0}(\\alpha X+\\beta Y) &=\\sum_{l=1}^{C_1}\\sum_{m=1}^{h}\\sum_{n=1}^{w}(\\alpha x_{l,(j-1)s_1+m,(k-1)s_2+n}+\\beta y_{l,(j-1)s_1+m,(k-1)s_2+n})\\cdot \\omega_{i,l,m,n},\\\\\n",
    "&=\\sum_{l=1}^{C_1}\\sum_{m=1}^{h}\\sum_{n=1}^{w}(\\alpha x_{l,(j-1)s_1+m,(k-1)s_2+n}\\cdot \\omega_{i,l,m,n}+\\beta y_{l,(j-1)s_1+m,(k-1)s_2+n}\\cdot \\omega_{i,l,m,n}),\\\\\n",
    "&=\\alpha\\sum_{l=1}^{C_1}\\sum_{m=1}^{h}\\sum_{n=1}^{w} x_{l,(j-1)s_1+m,(k-1)s_2+n}\\cdot \\omega_{i,l,m,n}+\\beta \\sum_{l=1}^{C_1}\\sum_{m=1}^{h}\\sum_{n=1}^{w}y_{l,(j-1)s_1+m,(k-1)s_2+n}\\cdot \\omega_{i,l,m,n},\\\\\n",
    "&=\\alpha \\operatorname{InfConv2d}_{W,0}(X)+\\beta \\operatorname{InfConv2d}_{W,0}(Y).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb89fac",
   "metadata": {},
   "source": [
    "#### Definition: Positional translation\n",
    "Given $\\delta\\in \\mathbb{Z}^2$ and a channel dimension $C\\in\\mathbb{N}$. We define the \"positional\" translation of $\\delta$ units as\n",
    "$$\n",
    "\\begin{align*}\n",
    "T^{C}_{\\delta}:  \\mathbb{R}^{C\\times \\mathbb{Z}^2}&\\longmapsto \\mathbb{R}^{C\\times \\mathbb{Z}^2} ,&\\quad \\text{where} \\quad   Y_{i,j,k}&=X_{i,j+\\delta_1,k+\\delta_2}.\\\\\n",
    " T^{C}_{\\delta} (X) &= Y & \n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff6acbe",
   "metadata": {},
   "source": [
    "### Property: $\\operatorname{InfConv2d}_{W,b}$ is translation-equivariant up to stride\n",
    "\n",
    "If $\\operatorname{InfConv2d}_{W,b}: \\mathbb{R}^{C_1\\times \\mathbb{Z}^2} \\longmapsto \\mathbb{R}^{C_2\\times \\mathbb{Z}^2}$ with stride $s$, then\n",
    "$$\\operatorname{InfConv2d}_{W,b}\\circ \\ T^{C_1}_{s*\\delta} = T^{C_2}_{\\delta}\\circ \\operatorname{InfConv2d}_{W,b}, \\quad \\forall\\delta \\in \\mathbb{Z}^2.$$\n",
    "\n",
    "In particular, for stride $s=(1,1)$, **full translation equivariance** holds.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cd49a54",
   "metadata": {},
   "source": [
    "Proof: Let $(i,j,k)\\in C\\times\\mathbb{Z}^2$ \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{InfConv2d}_{W,b}\\circ \\ T^{C_1}_{s*\\delta}(X)_{i,j,k}&=\\operatorname{InfConv2d}_{W,b}\\left( T^{C_1}_{s*\\delta}(X)\\right)_{i,j,k}\\omega_{i,l,m,n},\\\\\n",
    "&=b_{i} + \\sum_{l=1}^{C_1} \\sum_{m=1}^{h} \\sum_{n=1}^{w}\n",
    "T^{C_1}_{s*\\delta}(X)_{l,\\,(j-1)\\cdot s_1 + m,\\, (k-1)\\cdot s_2 + n}\\omega_{i,l,m,n},\\\\\n",
    "&=b_{i} + \\sum_{l=1}^{C_1} \\sum_{m=1}^{h} \\sum_{n=1}^{w}\n",
    "x_{l,\\,(j-1)\\cdot s_1 + m+s_1\\delta_1,\\, (k-1)\\cdot s_2 + n+s_2\\delta_2}\\omega_{i,l,m,n},\\\\\n",
    "&=b_{i} + \\sum_{l=1}^{C_1} \\sum_{m=1}^{h} \\sum_{n=1}^{w}\n",
    "x_{l,\\,(j+\\delta_1-1)\\cdot s_1 + m,\\, (k+\\delta_2-1)\\cdot s_2 + n}\\omega_{i,l,m,n},\\\\\n",
    "&=\\operatorname{InfConv2d}_{W,b}(X)_{i,j+\\delta_1,k+\\delta_2},\\\\\n",
    "&=T^{C_2}_{\\delta}(\\operatorname{InfConv2d}_{W,b}(X))_{i,j,k},\\\\\n",
    "&=T^{C_2}_{\\delta}\\circ\\operatorname{InfConv2d}_{W,b}(X)_{i,j,k}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then $\\operatorname{Conv2d}_{W,b}\\circ \\ T^{C_1}_{s*\\delta} = T^{C_2}_{\\delta}\\circ \\operatorname{Conv2d}_{W,b}$ and we conclude that $\\operatorname{InfConv2d}_{W,b}$ is translation equivariance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc832960",
   "metadata": {},
   "source": [
    "#### Definition: Padding operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bbaab7",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Pad}^{(p_1,p_2)}:\\bigcup_{H,W \\in \\mathbb{N}}\\mathbb{R}^{C\\times H\\times W}&\\longmapsto \\mathbb{R}^{C\\times \\mathbb{Z}^2}, \\\\\n",
    "\\operatorname{Pad}^{(p_1,p_2)} (X) &= Y\n",
    "\\end{align*}\n",
    "$$\n",
    "where\n",
    "$$\n",
    "Y_{i,j,k}=\\begin{cases} X_{i,j-p_1,k-p_2}, & p_1< j\\leq H+p_1, p_2 < k\\leq W+p_2, \\\\\n",
    "0,& \\text{otherwise} \\\\\n",
    "\\end{cases}\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccae531c",
   "metadata": {},
   "source": [
    "### Property: $\\operatorname{Pad}^{(p_1,p_2)}\\big|_{\\mathbb{R}^{C\\times H\\times W}}$ is linear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09521588",
   "metadata": {},
   "source": [
    "Proof: Let $\\alpha,\\beta \\in \\mathbb{R}$, $X,Y \\in \\mathbb{R}^{C\\times H\\times W}$, and $(i,j,k)\\in C\\times \\mathbb{Z}^2$ then \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Pad}^{(p_1,p_2)} (\\alpha X+ \\beta Y)_{i,j,k}&=\\begin{cases} \\alpha X_{i,j-p_1,k-p_2}+\\beta Y_{i,j-p_1,k-p_2}, & p_1< j\\leq H+p_1, p_2 < k\\leq W+p_2 \\\\\n",
    "0,& \\text{otherwise} \\\\\n",
    "\\end{cases}\\\\\n",
    "&=\\alpha\\begin{cases} X_{i,j-p_1,k-p_2}, & p_1< j\\leq H+p_1, p_2 < k\\leq W+p_2 \\\\\n",
    "0,& \\text{otherwise} \\\\\n",
    "\\end{cases}\\\\\n",
    "&+\\beta \\begin{cases}Y_{i,j-p_1,k-p_2}, & p_1< j\\leq H+p_1, p_2 < k\\leq W+p_2 \\\\\n",
    "0,& \\text{otherwise} \\\\\n",
    "\\end{cases}\\\\\n",
    "&=\\alpha\\operatorname{Pad}^{(p_1,p_2)} (X)_{i,j,k}+\\beta \\operatorname{Pad}^{(p_1,p_2)} (Y)_{i,j,k},\\\\\n",
    "&=(\\alpha\\operatorname{Pad}^{(p_1,p_2)} (X)+\\beta \\operatorname{Pad}^{(p_1,p_2)} (Y))_{i,j,k},\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    " \n",
    " Then $\\operatorname{Pad}^{(p_1,p_2)} (\\alpha X+ \\beta Y) = \\alpha\\operatorname{Pad}^{(p_1,p_2)} (X)+\\beta \\operatorname{Pad}^{(p_1,p_2)} (Y)$ and we conclude that $\\operatorname{Pad}^{(p_1,p_2)}\\big|_{\\mathbb{R}^{C\\times H\\times W}}$ is linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af3b925e",
   "metadata": {},
   "source": [
    "#### Definition: Crop operation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c54d5",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Crop}^{(*,H,W)}\\!: \\ \\ \\mathbb{R}^{C\\times\\mathbb{Z}^2}&\\longmapsto \\mathbb{R}^{C\\times H\\times W} ,\\\\\n",
    "\\operatorname{Crop}^{(*,H,W)} (X) &= Y\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where\n",
    "$$\n",
    "Y_{i,j,k}=X_{i,j,k}, \\quad  1\\leq j\\leq H, 1\\leq k\\leq W.\\\\\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4497a4",
   "metadata": {},
   "source": [
    "### Property: $\\operatorname{Crop}^{(*,H,W)}$ is linear "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b57e293",
   "metadata": {},
   "source": [
    "Proof: Let $\\alpha,\\beta \\in \\mathbb{R}$, $X,Y \\in \\mathbb{R}^{C\\times H\\times W}$, and $(i,j,k)\\in C\\times H \\times W$ then \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Crop}^{(*,H,W)}(\\alpha X+ \\beta Y)_{i,j,k}&=(\\alpha X+\\beta Y)_{i,j,k}, \\\\\n",
    "&=\\alpha X_{i,j,k}+\\beta Y_{i,j,k}, \\\\\n",
    "&=\\alpha\\operatorname{Crop}^{(*,H,W)} (X)_{i,j,k}+\\beta \\operatorname{Crop}^{(*,H,W)} (Y)_{i,j,k},\\\\\n",
    "&=(\\alpha\\operatorname{Crop}^{(*,H,W)} (X)+\\beta \\operatorname{Crop}^{(*,H,W)} (Y))_{i,j,k},\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    " \n",
    " Then $\\operatorname{Crop}^{(*,H,W)}(\\alpha X+ \\beta Y) = \\alpha\\operatorname{Crop}^{(*,H,W)}(X)+\\beta \\operatorname{Crop}^{(*,H,W)} (Y)$ and we conclude that $\\operatorname{Crop}^{(*,H,W)}$ is linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e427db",
   "metadata": {},
   "source": [
    "## Definition: Finite 2D Convolution (with padding)\n",
    "\n",
    "In practice we don't have \"inifinite\" tensors, we only can pass finite dimensional inputs to convolution, so we need a finite convolution definition\n",
    "\n",
    "Input  \n",
    "* $X \\in \\mathbb{R}^{C_1\\times H \\times W}, \\quad \\text{for } H,W\\in \\mathbb{N}.$  \n",
    "\n",
    "Weights  \n",
    "* kernel $W \\in \\mathbb{R}^{C_2\\times C_1 \\times h \\times w}$  \n",
    "* bias $b \\in \\mathbb{R}^{C_2}$  \n",
    "\n",
    "Hyperparameters  \n",
    "* stride $s=(s_1,s_2)$  \n",
    "* padding $p=(p_1,p_2)$  \n",
    "\n",
    "Output  \n",
    "* $\\operatorname{Conv2d}_{W,b} = \\operatorname{Crop}^{(*,H',W')}\\circ\\operatorname{InfConv2d}_{W,b}\\circ\\operatorname{Pad}^{(p_1,p_2)}$ \n",
    "\n",
    "where  \n",
    "$$\n",
    "\\begin{align*}\n",
    "H' &= \\left\\lfloor \\frac{H + 2p_1 - h}{s_1} \\right\\rfloor + 1, \\\\\n",
    "W' &= \\left\\lfloor \\frac{W + 2p_2 - w}{s_2} \\right\\rfloor + 1.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Notice that the indexes position $(j,k): j<1,j>H+2p_1, k<1$, or $k>W+2p_2$ are created by the padding and then deleted by the Crop. So we can simplified the formulation as follow   \n",
    "\n",
    "Output  \n",
    "* $\\operatorname{Conv2d}_{W,b}(X) = O \\in \\mathbb{R}^{C_2 \\times H' \\times W'}$, where  \n",
    "\n",
    "$$\n",
    "\\begin{align*}\n",
    "O_{i,j,k} &= b_{i} + \\sum_{l=1}^{C_1} \\sum_{m=1}^{h} \\sum_{n=1}^{w}\n",
    "\\tilde{x}_{l,\\,(j-1)\\cdot s_1 + m,\\, (k-1)\\cdot s_2 + n}\\,\n",
    "\\omega_{i,l,m,n}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "where $\\tilde{X} \\in \\mathbb{R}^{C_1 \\times (H + 2p_1) \\times (W + 2p_2)}$ is $X$ padded with $p_1$ zeros on the top and bottom and $p_2$ zeros on the left and right for each channel: \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Pad}(X)&=\\tilde{X},\\\\\n",
    "\\tilde{X}_{i,:,:} & = \\begin{pmatrix} \n",
    "0_{p_1\\!\\times p_2} & 0_{p_1\\!\\times W} & 0_{p_1\\!\\times p_2},\\\\\n",
    "0_{H \\!\\times p_2} & X_{i,:,:} & 0_{H \\!\\times p_2},\\\\\n",
    "0_{p_1\\!\\times p_2} & 0_{p_1\\!\\times W} & 0_{p_1\\!\\times p_2},\\\\\n",
    "\\end{pmatrix}, \\quad i=1,2,\\dots,C_1.\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b15d26",
   "metadata": {},
   "source": [
    "**Note:** The same convolution function can be applied to inputs of different spatial shapes. The model parameters are not tied to specific coordinates. In this sense, $\\operatorname{Conv2d}_{W,b}$ is **position-agnostic**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1488a09",
   "metadata": {},
   "source": [
    "### Property: $\\operatorname{Conv2d}_{W,0}\\big|_{\\mathbb{R}^{C\\times H\\times W}}$ is linear and $\\operatorname{Conv2d}_{W,b}\\big|_{\\mathbb{R}^{C\\times H\\times W}}$ is affine "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359f5604",
   "metadata": {},
   "source": [
    "Proof: Notice that \n",
    "$$\n",
    "\\begin{align*}\n",
    "\\operatorname{Conv2d}_{W,b}\\big|_{\\mathbb{R}^{C\\times H\\times W}}=\\operatorname{Crop}^{(*,H',W')}\\circ\\operatorname{InfConv2d}_{W,b}\\circ(\\operatorname{Pad}^{(p_1,p_2)}\\big|_{\\mathbb{R}^{C\\times H\\times W}})\n",
    "\\end{align*}\n",
    "$$\n",
    "Then the results comes directly from the previous results: \n",
    "* $\\operatorname{Crop}^{(*,H',W')}$ is linear, \n",
    "* $\\operatorname{Pad}^{(p_1,p_2)}\\big|_{\\mathbb{R}^{C\\times H\\times W}}$ is linear  \n",
    "* $\\operatorname{InfConv2d}_{W,0}$ is linear and $\\operatorname{InfConv2d}_{W,b}$ is affine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e17573a",
   "metadata": {},
   "source": [
    "## Code: $\\operatorname{Conv2d}_{W,b}$\n",
    "\n",
    "$\\operatorname{InfConv2d}_{W,b}$ requires infinite dimentional inputs so it has only theoretical meaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3b9802e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "class Conv2d(nn.Module):\n",
    "    \"\"\"\n",
    "    This version is designed for readability and to expose the internal logic of\n",
    "    the convolution operation. It behaves similarly to `torch.nn.Conv2d` but may differ slightly in numerical results and performance due to the use of explicit Python loops and the absence of low-levelo ptimizations such as vectorized kernels or memoryâ€efficient stride operations.\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size,\n",
    "                 stride=1, padding=0, bias=True, device=None, dtype=None):\n",
    "        super().__init__()\n",
    "        factory_kwargs = {\"device\": device, \"dtype\": dtype}\n",
    "\n",
    "        # Normalize tuple inputs\n",
    "        if isinstance(kernel_size, int):\n",
    "            kernel_size = (kernel_size, kernel_size)\n",
    "        if isinstance(stride, int):\n",
    "            stride = (stride, stride)\n",
    "        if isinstance(padding, int):\n",
    "            padding = (padding, padding)\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.padding = padding\n",
    "\n",
    "        # Learnable parameters\n",
    "        weight_shape = (out_channels, in_channels, *kernel_size)\n",
    "        self.weight = nn.Parameter(torch.empty(weight_shape, **factory_kwargs))\n",
    "        if bias:\n",
    "            self.bias = nn.Parameter(torch.empty(out_channels, **factory_kwargs))\n",
    "        else:\n",
    "            self.register_parameter(\"bias\", None)\n",
    "\n",
    "        # Kaiming initialization (no activvation function assumed)\n",
    "        nn.init.kaiming_uniform_(self.weight, a=math.sqrt(5))\n",
    "        # bias initialization (fan_in needs to be computed manually because bias is broadcasted in conv computation)\n",
    "        if self.bias is not None:\n",
    "            fan_in = in_channels * kernel_size[0] * kernel_size[1]\n",
    "            bound = 1 / math.sqrt(fan_in)\n",
    "            nn.init.uniform_(self.bias, -bound, bound)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        N, C, H, W = x.shape\n",
    "        h, w = self.kernel_size\n",
    "        sH, sW = self.stride\n",
    "        pH, pW = self.padding\n",
    "        Hpad, Wpad = H + 2 * pH, W + 2 * pW\n",
    "        H_out = (Hpad - h) // sH + 1\n",
    "        W_out = (Wpad - w) // sW + 1\n",
    "\n",
    "        if pH > 0 or pW > 0:\n",
    "            x = torch.nn.functional.pad(x, (pW, pW, pH, pH))\n",
    "\n",
    "        out = x.new_zeros((N, self.out_channels, H_out, W_out))\n",
    "\n",
    "        for n in range(N):  # batch\n",
    "            for oc in range(self.out_channels):  # each filter\n",
    "                for i in range(H_out):\n",
    "                    for j in range(W_out):\n",
    "                        # top-left corner of the sliding window in the input\n",
    "                        h_start = i * sH\n",
    "                        w_start = j * sW\n",
    "                        # get the input patch: (C_in, h, w)\n",
    "                        x_patch = x[n, :, h_start:h_start + h, w_start:w_start + w]\n",
    "                        # corresponding filter: (C_in, kH, kW)\n",
    "                        w_filter = self.weight[oc]\n",
    "                        # elementwise mul + sum\n",
    "                        val = (x_patch * w_filter).sum()\n",
    "                        if self.bias is not None:\n",
    "                            val = val + self.bias[oc]\n",
    "                        out[n, oc, i, j] = val\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8933e90d",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef734441",
   "metadata": {},
   "outputs": [],
   "source": [
    "in_channels=3\n",
    "out_channels=2\n",
    "kernel_size=3\n",
    "stride=1\n",
    "padding=1\n",
    "\n",
    "batch_size=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f914a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "nn_conv = torch.nn.Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding)\n",
    "torch.manual_seed(0)\n",
    "conv = Conv2d(\n",
    "            in_channels,\n",
    "            out_channels,\n",
    "            kernel_size,\n",
    "            stride,\n",
    "            padding)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95b767f9",
   "metadata": {},
   "source": [
    "## Weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "baf5b3c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight torch.Size([2, 3, 3, 3])\n",
      "bias torch.Size([2])\n",
      "weight torch.Size([2, 3, 3, 3])\n",
      "bias torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "for name, param in nn_conv.named_parameters():\n",
    "    print(name, param.shape)\n",
    "for name, param in nn_conv.named_parameters():\n",
    "    print(name, param.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23ce3dfe",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8f60f278",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 2, 5, 5])\n",
      "nn_out=tensor([[[[ 7.2256e-01,  4.7931e-01,  2.5764e-01,  1.0786e-01,  2.3769e-01],\n",
      "          [ 4.3293e-01, -5.5113e-01, -5.2614e-01,  1.2842e-01,  4.7790e-01],\n",
      "          [-8.3026e-02,  5.7491e-02,  3.7660e-01,  2.9996e-01,  3.0393e-01],\n",
      "          [-2.6451e-01,  3.7914e-01, -4.1412e-01, -5.8225e-01, -8.7871e-02],\n",
      "          [ 9.8623e-02,  3.3075e-01,  9.0158e-02,  2.6753e-01,  4.3898e-01]],\n",
      "\n",
      "         [[-4.1536e-01, -7.8316e-01,  5.8771e-04, -2.3633e-01, -1.2479e-01],\n",
      "          [-3.1154e-01, -1.0928e-01,  7.6909e-02, -5.1875e-01, -5.6017e-02],\n",
      "          [-5.2234e-01, -9.7939e-01, -1.7672e+00, -1.0495e+00,  2.2939e-01],\n",
      "          [ 6.5900e-01, -4.5323e-02, -9.6968e-02,  5.7606e-02,  1.7291e-01],\n",
      "          [-8.4375e-01, -6.4110e-01, -4.6406e-01, -7.2019e-01, -1.0202e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3865e-01,  6.1891e-01,  4.5421e-01, -6.6918e-01,  4.3518e-01],\n",
      "          [ 6.3658e-02,  1.3600e-02,  2.8060e-01,  2.3520e-01,  4.1093e-01],\n",
      "          [ 1.2209e-01, -1.1107e+00,  6.0998e-01, -8.9475e-03,  1.6732e-01],\n",
      "          [ 5.9267e-01,  7.2204e-01,  3.1039e-01,  6.4367e-02, -4.0299e-01],\n",
      "          [-1.0377e-01,  1.8145e-01,  1.1894e-01,  6.9919e-01,  1.1715e-01]],\n",
      "\n",
      "         [[-6.5378e-01, -5.8242e-01,  2.6635e-01, -4.4588e-01, -1.3912e-01],\n",
      "          [-9.1097e-01, -1.0375e+00, -6.9970e-02, -8.6491e-01, -1.4906e-01],\n",
      "          [ 4.7098e-01,  1.8029e-01, -5.9531e-01, -8.2732e-01,  1.0215e-01],\n",
      "          [-2.7469e-01, -8.9693e-02, -7.3554e-01,  3.1242e-02,  1.4988e-01],\n",
      "          [-1.1064e-01, -2.4091e-01, -8.6637e-01, -4.5083e-01, -4.9487e-01]]]],\n",
      "       grad_fn=<ConvolutionBackward0>)\n",
      "torch.Size([2, 2, 5, 5])\n",
      "out=tensor([[[[ 7.2256e-01,  4.7930e-01,  2.5764e-01,  1.0786e-01,  2.3769e-01],\n",
      "          [ 4.3293e-01, -5.5113e-01, -5.2614e-01,  1.2842e-01,  4.7790e-01],\n",
      "          [-8.3026e-02,  5.7491e-02,  3.7660e-01,  2.9996e-01,  3.0393e-01],\n",
      "          [-2.6451e-01,  3.7914e-01, -4.1412e-01, -5.8225e-01, -8.7871e-02],\n",
      "          [ 9.8623e-02,  3.3075e-01,  9.0158e-02,  2.6753e-01,  4.3898e-01]],\n",
      "\n",
      "         [[-4.1536e-01, -7.8316e-01,  5.8769e-04, -2.3633e-01, -1.2479e-01],\n",
      "          [-3.1154e-01, -1.0928e-01,  7.6909e-02, -5.1875e-01, -5.6017e-02],\n",
      "          [-5.2234e-01, -9.7939e-01, -1.7672e+00, -1.0495e+00,  2.2939e-01],\n",
      "          [ 6.5900e-01, -4.5323e-02, -9.6968e-02,  5.7606e-02,  1.7291e-01],\n",
      "          [-8.4375e-01, -6.4110e-01, -4.6406e-01, -7.2019e-01, -1.0202e+00]]],\n",
      "\n",
      "\n",
      "        [[[ 7.3865e-01,  6.1891e-01,  4.5421e-01, -6.6918e-01,  4.3518e-01],\n",
      "          [ 6.3658e-02,  1.3600e-02,  2.8060e-01,  2.3520e-01,  4.1093e-01],\n",
      "          [ 1.2209e-01, -1.1107e+00,  6.0998e-01, -8.9475e-03,  1.6732e-01],\n",
      "          [ 5.9267e-01,  7.2204e-01,  3.1039e-01,  6.4367e-02, -4.0299e-01],\n",
      "          [-1.0377e-01,  1.8145e-01,  1.1894e-01,  6.9919e-01,  1.1715e-01]],\n",
      "\n",
      "         [[-6.5378e-01, -5.8242e-01,  2.6635e-01, -4.4588e-01, -1.3912e-01],\n",
      "          [-9.1098e-01, -1.0375e+00, -6.9970e-02, -8.6491e-01, -1.4906e-01],\n",
      "          [ 4.7098e-01,  1.8029e-01, -5.9531e-01, -8.2732e-01,  1.0215e-01],\n",
      "          [-2.7469e-01, -8.9692e-02, -7.3554e-01,  3.1242e-02,  1.4988e-01],\n",
      "          [-1.1064e-01, -2.4091e-01, -8.6637e-01, -4.5083e-01, -4.9487e-01]]]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(batch_size, in_channels, 5, 5)\n",
    "nn_out = nn_conv(x)\n",
    "out = conv(x)\n",
    "print(f\"{nn_out.shape}\\n{nn_out=}\")\n",
    "print(f\"{out.shape}\\n{out=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5afe8cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
