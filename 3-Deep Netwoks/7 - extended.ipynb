{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5a56b223",
   "metadata": {},
   "source": [
    "# Building a Deep Network in PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b3b363",
   "metadata": {},
   "source": [
    "### Prerequisite:\n",
    "\n",
    "Download the data from [here](https://drive.google.com/file/d/1czcJcoG06uT7-xF2_3mr9uBV3qVVb6Tg/view)\n",
    "and unzip it to `deeplearning_v2/dataset/dogs_and_cats/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cdf0e2d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:21.698780Z",
     "iopub.status.busy": "2024-06-09T08:00:21.698582Z",
     "iopub.status.idle": "2024-06-09T08:00:23.372734Z",
     "shell.execute_reply": "2024-06-09T08:00:23.372229Z"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utdl'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m      6\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mPIL\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Image\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mutdl\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m loader\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'utdl'"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from PIL import Image\n",
    "from utdl.data import loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df0cbff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.374969Z",
     "iopub.status.busy": "2024-06-09T08:00:23.374749Z",
     "iopub.status.idle": "2024-06-09T08:00:23.397637Z",
     "shell.execute_reply": "2024-06-09T08:00:23.397141Z"
    }
   },
   "outputs": [],
   "source": [
    "def visualize_image(img):\n",
    "    img = img.numpy()\n",
    "    img = (img.transpose(1, 2, 0) * 255).astype(np.uint8)\n",
    "\n",
    "    return Image.fromarray(img)\n",
    "\n",
    "\n",
    "transform = loader.get_transform(resize=(32, 32))\n",
    "input_size = 32 * 32 * 3\n",
    "train_dataset = loader.get_dataset(\"dogs_and_cats\", \"train\", transform=transform)\n",
    "\n",
    "visualize_image(train_dataset[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b915d28",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.400175Z",
     "iopub.status.busy": "2024-06-09T08:00:23.399980Z",
     "iopub.status.idle": "2024-06-09T08:00:23.417189Z",
     "shell.execute_reply": "2024-06-09T08:00:23.416661Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define a two-layer perceptron\n",
    "class TwoLayerPerceptron(torch.nn.Module):\n",
    "    def __init__(self, n_hidden=100):\n",
    "        super().__init__()\n",
    "        self.hidden = torch.nn.Linear(input_size, n_hidden)\n",
    "        self.activation = torch.nn.ReLU()\n",
    "        self.output = torch.nn.Linear(n_hidden, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.output(self.activation(self.hidden(x.view(-1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3be8d900",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.419717Z",
     "iopub.status.busy": "2024-06-09T08:00:23.419532Z",
     "iopub.status.idle": "2024-06-09T08:00:23.442412Z",
     "shell.execute_reply": "2024-06-09T08:00:23.441961Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [],
   "source": [
    "# Let's create such a two-layer perceptron with 100 hidden units\n",
    "net1 = TwoLayerPerceptron(100)\n",
    "# We can pass an image through it and get the output logit\n",
    "x, y = train_dataset[0]\n",
    "print(f\"net1 output: {net1(x).view(-1).detach().numpy()[0]} gt_label: {y}\")\n",
    "visualize_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97399a40",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.445016Z",
     "iopub.status.busy": "2024-06-09T08:00:23.444701Z",
     "iopub.status.idle": "2024-06-09T08:00:23.473907Z",
     "shell.execute_reply": "2024-06-09T08:00:23.473286Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now let's pass another image through it and get the output logit\n",
    "x, y = train_dataset[199]\n",
    "print(f\"net1 output: {net1(x).view(-1).detach().numpy()[0]} gt_label: {y}\")\n",
    "visualize_image(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8f0e99",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.477155Z",
     "iopub.status.busy": "2024-06-09T08:00:23.476838Z",
     "iopub.status.idle": "2024-06-09T08:00:23.519464Z",
     "shell.execute_reply": "2024-06-09T08:00:23.518785Z"
    }
   },
   "outputs": [],
   "source": [
    "# When the network goes deeper, it can be painful to explicitly call each layer one by one.\n",
    "# We can wrap layers into one module with a torch.nn.Sequential container\n",
    "class MLP(torch.nn.Module):\n",
    "    def __init__(self, input_size, *hidden_size):\n",
    "        super().__init__()\n",
    "        layers = []\n",
    "        # Add hidden layers\n",
    "        n_in = input_size\n",
    "        for n_out in hidden_size:\n",
    "            layers.append(torch.nn.Linear(n_in, n_out))\n",
    "            layers.append(torch.nn.ReLU())\n",
    "            n_in = n_out\n",
    "        # Add the output layer\n",
    "        layers.append(torch.nn.Linear(n_out, 1))\n",
    "\n",
    "        # Use torch.nn.Sequential to create a small model,\n",
    "        # where the layers are connected in a cascading way.\n",
    "        # The order they are passed in the constructor\n",
    "        self.network = torch.nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.network(x.view(-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc73145",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-06-09T08:00:23.522683Z",
     "iopub.status.busy": "2024-06-09T08:00:23.522438Z",
     "iopub.status.idle": "2024-06-09T08:00:23.555890Z",
     "shell.execute_reply": "2024-06-09T08:00:23.555294Z"
    }
   },
   "outputs": [],
   "source": [
    "# Let's create such a four-layer perceptron with 100, 50, 50 hidden units for each layer\n",
    "net1 = MLP(input_size, 100, 50, 50)\n",
    "# We can pass an image through it and get the output logit\n",
    "x, y = train_dataset[0]\n",
    "print(f\"net1 output: {net1(x).view(-1).detach().numpy()[0]} gt_label: {y}\")\n",
    "visualize_image(x)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "custom_cell_magics": "kql",
   "notebook_metadata_filter": "title"
  },
  "kernelspec": {
   "display_name": "learn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "title": "Deep Networks in PyTorch"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
