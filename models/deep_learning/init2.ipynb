{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a11f78e4",
   "metadata": {},
   "source": [
    "## Property: Constant initialization does not work\n",
    "\n",
    "Constant $0$ initialization could be a good idea because no bias is introduced but this creates a symetry in the weights that gradients updates can't break."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d88de1",
   "metadata": {},
   "source": [
    "\n",
    "Consider a simple two layer multilayer perceptrom\n",
    "$$\\text{Linear2}_{W^{(2)},b^{(2)}}(\\text{Activtion}(\\text{Linear1}_{W^{(1)},b^{(1)}}(x)))$$\n",
    "where\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\text{Linear1}_{W^{(1)},b^{(1)}}(x)&=W^{(1)}x+b^{(1)},\\\\\n",
    "\\text{Linear2}_{W^{(2)},b^{(1)}}(x)&=W^{(2)}x+b^{(2)},\n",
    "\\end{align*}\n",
    "$$\n",
    "and $\\text{Activtion}$ is an arbitrary real function applied componentwise over vectors. \n",
    "\n",
    "Consider the properties\n",
    "* $W^{(1)}$ has constant columns (i.e. $W^{(1)}_{i,j}=c^{(1)}_j, \\ \\forall\\ i,j$)\n",
    "* $b^{(1)}$ is constant (i.e. $b^{(1)}_{i}=d^{(1)}, \\ \\forall\\ i$)\n",
    "* $W^{(2)}$ is constant (i.e. $W^{(2)}_{i,j}=c^{(2)}, \\ \\forall\\ i,j$)\n",
    "* $b^{(2)}$ is constant (i.e. $b^{(2)}_{i}=d^{(2)}, \\ \\forall\\ i$)\n",
    "\n",
    "We assume alse that the loss funciton is permutation invariant $\\text{loss}(\\pi(x))=\\text{loss}(\\pi(x))$ for any (index) permutation $x$. This is not restrictive at all. It is easy to check that Mean square loss is permutation equivariant \n",
    "$$\\text{MSE}(\\pi(x))=\\sum_{i=1}x_{\\pi(i)}^2=\\sum_{i=1}x_{i}^2=\\text{MSE}(x).$$\n",
    "This implies that the derivative are equal\n",
    "$$\\frac{\\partial f}{x_{j}}(x)=\\lim_{h\\to0}\\frac{f(x+he_{j})-f(x)}{h}=\\lim_{h\\to0}\\frac{f(x+he_{i})-f(x)}{h}=\\frac{\\partial f}{x_{i}}(x),$$\n",
    "where in the second equlity weappliy the permutation that swap $i$ and $j$.\n",
    "\n",
    "Under this condition, if the initial weights satiesfy these properties then, these properties are preserved along epochs (after the weights are updated with the gradient information)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f84ed3",
   "metadata": {},
   "source": [
    "**Proof:**\n",
    "Consider\n",
    "* $W^{(1)}_{i,j}=c^{(1)}_j, \\ \\forall\\ i,j$\n",
    "* $b^{(1)}_{i}=d^{(1)}, \\ \\forall\\ i$\n",
    "* $W^{(2)}_{i,j}=c^{(2)}, \\ \\forall\\ i,j$\n",
    "* $b^{(2)}_{i}=d^{(2)}, \\ \\forall\\ i$\n",
    "\n",
    "and let's adopt the following notatioin:\n",
    "\\begin{align*}\n",
    "y^{(1)} &= \\text{Linear1}_{W^{(1)},b^{(1)}}(x),\\\\\n",
    "y^{(a)} &= \\text{Activtion}(y^{(1)}),\\\\\n",
    "y^{(2)} &= \\text{Linear2}_{W^{(2)},b^{(2)}}(y^{(a)}).\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59ebe636",
   "metadata": {},
   "source": [
    "First notice that under this properites the output of the first layer is constant:\n",
    "$$\n",
    "\\begin{align*}\n",
    "y^{(1)}&=\\text{Linear1}_{W^{(1)},b^{(1)}}(x),\\\\\n",
    "&=W^{(1)}x+b^{(1)}=\\begin{pmatrix}\n",
    "\\sum_{j}w^{(1)}_{1,j}x_j +b^{(1)}_1\\\\ \n",
    "\\sum_{j}w^{(1)}_{2,j}x_j +b^{(1)}_2\\\\ \n",
    "\\vdots\\\\\n",
    "\\sum_{j}w^{(1)}_{N_1,j}x_j +b^{(1)}_{N_1}\\\\ \n",
    "\\end{pmatrix}\n",
    "=\\begin{pmatrix}\n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\vdots\\\\\n",
    "\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\\\ \n",
    "\\end{pmatrix}\\\\\n",
    "&=\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_1}.\\\\\n",
    "y^{(a)}&=\\text{Activation}(y^{(1)}),\\\\\n",
    "&=\\text{Activation}\\left(\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_a}\\right),\\\\\n",
    "&=\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)1_{N_a},\\\\\n",
    "y^{(2)}&=\\text{Linear1}_{W^{(2)},b^{(2)}}(y^{(a)}),\\\\\n",
    "&=W^{(2)}y^{(a)}+b^{(2)},\\\\\n",
    "&=\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)W^{(2)}1_{N_2}+b^{(2)},\\\\\n",
    "&=\\left(N_2c^{(2)}\\text{Activation}\\left(\\sum_{j}c^{(1)}_{j}x_j +d^{(1)}\\right)+d^{(2)}\\right)1_{N_2}.\n",
    "\\end{align*}\\\\\n",
    "$$\n",
    "So, all the vectors $y^{(1)},y^{(a)},y^{(2)}$ are constant. Let's denote for all $i$-th component $y^{(1)}_i=o^{(1)}$,$y^{(a)}_i=o^{(a)}$ and $y_i^{(2)}=o^{(2)}$, then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a61394f",
   "metadata": {},
   "source": [
    "Then\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial w^{(1)}_{i,j}}&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}\\frac{\\partial y^{(2)}}{\\partial y^{(a)}_{i}}\\frac{\\partial y^{(a)}_{i}}{\\partial y^{(1)}_{i}}\\frac{\\partial y^{(1)}_{i}}{\\partial w^{(1)}_{i,j}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}W^{(2)}_{:,i}\\frac{\\partial \\text{Activation}}{\\partial x_{i}}(y^{(1)}_i)x_j,\\\\\n",
    "\n",
    "&=\\left(\\sum_k\\frac{\\partial \\text{loss}}{\\partial y_k}(y^{(2)}_k)W^{(2)}_{k,i}\\right)\\frac{\\partial \\text{Activation}}{\\partial x}(o^{(1)})x_j,\\\\\n",
    "&=N_2\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})c^{(2)}\\frac{\\partial \\text{Activation}}{\\partial x}\\left(o^{(1)}\\right)x_j,\\\\\n",
    "\\end{align*}\n",
    "$$\n",
    "Then $\\frac{\\partial \\text{loss}}{\\partial w^{(1)}_{i,j}}$ is constant along index $i$ and consequently $W^{(1)}$ has constant columns after being updated. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd389e1",
   "metadata": {},
   "source": [
    "The results forthe bias $b^{(1)}$ is analogous, notice that\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial b^{(1)}_{i}}&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}\\frac{\\partial y^{(2)}}{\\partial y^{(a)}_{i}}\\frac{\\partial y^{(a)}_{i}}{\\partial y^{(1)}_{i}}\\frac{\\partial y^{(1)}_{i}}{\\partial b^{(1)}_{i}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y^{(2)}}W^{(2)}_{:,i}\\frac{\\partial \\text{Activation}}{\\partial x_{i}}(y^{(1)}_i)\\cdot 1,\\\\\n",
    "&=\\left(\\sum_k\\frac{\\partial \\text{loss}}{\\partial y_k}(y^{(2)}_k)W^{(2)}_{k,i}\\right)\\frac{\\partial \\text{Activation}}{\\partial x}\\left(\\sum_{k}c^{(1)}_{k}x_k+d^{(1)}\\right),\\\\\n",
    "&=N_2\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})c^{(2)}\\frac{\\partial \\text{Activation}}{\\partial x}\\left(\\sum_{k}c^{(1)}_{k}x_k+d^{(1)}\\right).\n",
    "\\end{align*}\n",
    "$$\n",
    "So, $\\frac{\\partial \\text{loss}}{\\partial b^{(1)}_{i}}$ is independent of $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2965f9cb",
   "metadata": {},
   "source": [
    "For the second weights we have\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial W^{(2)}_{i,j}}&=\\frac{\\partial \\text{loss}}{\\partial y_i^{(2)}}\\frac{\\partial y_i^{(2)}}{\\partial W^{(2)}_{i,j}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y_i}(y_i^{(2)})y^{(a)}_j,\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)})o^{(a)}.\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Finally, for the bias wehave\n",
    "$$\n",
    "\\begin{align*}\n",
    "\\frac{\\partial \\text{loss}}{\\partial b^{(2)}_{i}}&=\\frac{\\partial \\text{loss}}{\\partial y_i^{(2)}}\\frac{\\partial y_i^{(2)}}{\\partial b^{(2)}_{i}},\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y_i}(y_i^{(2)})\\cdot 1,\\\\\n",
    "&=\\frac{\\partial \\text{loss}}{\\partial y}(o^{(2)}).\n",
    "\\end{align*}\n",
    "$$\n",
    "\n",
    "Then all four properties are preserved after adding an scaled gradiant vector."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5f8815c",
   "metadata": {},
   "source": [
    "## Code: Constant initializtion does not work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0a42e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f4586e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConstInit(nn.Module):\n",
    "    def __init__(self, init_w: float,init_b: float,layer_dims = [3,2,4],bias: bool = False):\n",
    "        super().__init__()  \n",
    "        d1,d2,d3 = layer_dims\n",
    "        self.linear1 = nn.Linear(d1, d2,bias=bias)\n",
    "        self.linear2 = nn.Linear(d2, d3,bias=bias)\n",
    "        if bias:\n",
    "            nn.init.constant_(self.linear1.bias, init_b)\n",
    "            nn.init.constant_(self.linear2.bias, init_b)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Each column j gets value init_value + j\n",
    "        col_values = init_w + torch.arange(d1).float()  # shape (in_f,)\n",
    "\n",
    "        # Repeat for each row\n",
    "        W = col_values.unsqueeze(0).repeat(d2, 1)  # shape (out_f, in_f)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            self.linear1.weight.copy_(W)\n",
    "      \n",
    "        nn.init.constant_(self.linear2.weight, init_w)  \n",
    "    \n",
    "    def print_parameters(self):\n",
    "        for name , w in self.named_parameters():\n",
    "            print(name, w)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x1 = self.linear1(x)\n",
    "        x_relu = self.relu(x1)\n",
    "        x2= self.linear2(x_relu)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a8f0966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([0.5000, 0.5000], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.5000, 0.5000, 0.5000, 0.5000], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "net = ConstInit(init_w=1.0,init_b=0.5,bias=True)\n",
    "net.print_parameters()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ce87575",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4a0d52d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output: tensor([[ 2.4345,  2.4345,  2.4345,  2.4345],\n",
      "        [ 4.6449,  4.6449,  4.6449,  4.6449],\n",
      "        [17.5254, 17.5254, 17.5254, 17.5254],\n",
      "        [ 0.5000,  0.5000,  0.5000,  0.5000]], grad_fn=<AddmmBackward0>)\n",
      "Target: tensor([[1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.],\n",
      "        [1., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(4, 3)\n",
    "y = torch.full((4, 4), 1.0)\n",
    "out = net(x)\n",
    "print(\"Output:\", out)\n",
    "print(\"Target:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "af4f703c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.1)\n",
    "loss_fn = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "041ab103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "linear1.weight Parameter containing:\n",
      "tensor([[-0.2417,  1.4247,  1.4839],\n",
      "        [-0.2417,  1.4247,  1.4839]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-0.5802, -0.5802], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[-0.8702, -0.8702],\n",
      "        [-0.8702, -0.8702],\n",
      "        [-0.8702, -0.8702],\n",
      "        [-0.8702, -0.8702]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.2362, 0.2362, 0.2362, 0.2362], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.6030, 0.6030, 0.6030, 0.6030], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.7228, 0.7228, 0.7228, 0.7228], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([0.8867, 0.8867, 0.8867, 0.8867], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.0923, 1.0923, 1.0923, 1.0923], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.3377, 1.3377, 1.3377, 1.3377], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.6208, 1.6208, 1.6208, 1.6208], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([1.9398, 1.9398, 1.9398, 1.9398], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([2.2928, 2.2928, 2.2928, 2.2928], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([2.6782, 2.6782, 2.6782, 2.6782], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([3.0943, 3.0943, 3.0943, 3.0943], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([3.5395, 3.5395, 3.5395, 3.5395], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([4.0126, 4.0126, 4.0126, 4.0126], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([4.5119, 4.5119, 4.5119, 4.5119], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([5.0363, 5.0363, 5.0363, 5.0363], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([5.5845, 5.5845, 5.5845, 5.5845], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([6.1553, 6.1553, 6.1553, 6.1553], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([6.7475, 6.7475, 6.7475, 6.7475], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([7.3602, 7.3602, 7.3602, 7.3602], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([7.9921, 7.9921, 7.9921, 7.9921], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([8.6425, 8.6425, 8.6425, 8.6425], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([9.3104, 9.3104, 9.3104, 9.3104], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([9.9949, 9.9949, 9.9949, 9.9949], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([10.6952, 10.6952, 10.6952, 10.6952], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([11.4104, 11.4104, 11.4104, 11.4104], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([12.1399, 12.1399, 12.1399, 12.1399], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([12.8829, 12.8829, 12.8829, 12.8829], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([13.6387, 13.6387, 13.6387, 13.6387], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([14.4068, 14.4068, 14.4068, 14.4068], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([15.1865, 15.1865, 15.1865, 15.1865], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([15.9771, 15.9771, 15.9771, 15.9771], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([16.7783, 16.7783, 16.7783, 16.7783], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([17.5894, 17.5894, 17.5894, 17.5894], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([18.4099, 18.4099, 18.4099, 18.4099], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([19.2394, 19.2394, 19.2394, 19.2394], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([20.0774, 20.0774, 20.0774, 20.0774], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([20.9236, 20.9236, 20.9236, 20.9236], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([21.7774, 21.7774, 21.7774, 21.7774], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([22.6385, 22.6385, 22.6385, 22.6385], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([23.5066, 23.5066, 23.5066, 23.5066], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([24.3813, 24.3813, 24.3813, 24.3813], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([25.2622, 25.2622, 25.2622, 25.2622], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([26.1491, 26.1491, 26.1491, 26.1491], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([27.0416, 27.0416, 27.0416, 27.0416], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([27.9396, 27.9396, 27.9396, 27.9396], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([28.8426, 28.8426, 28.8426, 28.8426], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([29.7504, 29.7504, 29.7504, 29.7504], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([30.6629, 30.6629, 30.6629, 30.6629], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([31.5798, 31.5798, 31.5798, 31.5798], requires_grad=True)\n",
      "linear1.weight Parameter containing:\n",
      "tensor([[-2.0083, -1.1648, -0.1156],\n",
      "        [-2.0083, -1.1648, -0.1156]], requires_grad=True)\n",
      "linear1.bias Parameter containing:\n",
      "tensor([-1.8569, -1.8569], requires_grad=True)\n",
      "linear2.weight Parameter containing:\n",
      "tensor([[0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360],\n",
      "        [0.5360, 0.5360]], requires_grad=True)\n",
      "linear2.bias Parameter containing:\n",
      "tensor([32.5008, 32.5008, 32.5008, 32.5008], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for i in range(50):\n",
    "    loss = loss_fn(net(x+i), y+i)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    net.print_parameters()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-notebook",
   "language": "python",
   "name": "ml-notebook"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
